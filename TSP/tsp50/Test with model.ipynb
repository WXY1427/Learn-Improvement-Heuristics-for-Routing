{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboard_logger import Logger as TbLogger\n",
    "\n",
    "from critic_network import CriticNetwork\n",
    "from options import get_options\n",
    "from test_function import validate, get_inner_model\n",
    "from baselines import CriticBaseline\n",
    "from attention_model import AttentionModel\n",
    "from utils import torch_load_cpu, load_model, maybe_cuda_model, load_problem\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test instance with changed graph size, seed, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run options --graph_size 50 --seed 1234 --steps 1000 --eval_only --load_path outputs/tsp_50/run/epoch-198.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "torch.manual_seed(opts.seed)\n",
    "\n",
    "# Figure out what's the problem\n",
    "problem = load_problem(opts.problem)\n",
    "\n",
    "val_dataset = problem.make_dataset(size=opts.graph_size, num_samples=opts.val_size, filename=opts.val_dataset)\n",
    "# torch.save(val_dataset,'multi.pt')\n",
    "# val_dataset=torch.load('multi.pt')[0:1000]\n",
    "# val_dataset=val_dataset[0:1000]\n",
    "# val_dataset = val_dataset[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading data from outputs/tsp_50/run/epoch-197.pt\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaoxin/.local/lib/python3.5/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test, took 00:03:03 s\n",
      "Validating...\n",
      "Test, took 00:03:02 s\n",
      "Validating...\n",
      "Test, took 00:02:49 s\n",
      "Validating...\n",
      "Test, took 00:02:49 s\n",
      "Validating...\n",
      "Test, took 00:02:56 s\n",
      "Validating...\n",
      "Test, took 00:04:26 s\n",
      "Validating...\n",
      "Test, took 00:04:31 s\n",
      "Validating...\n",
      "Test, took 00:04:29 s\n",
      "Best solutions: 5.745500087738037 +- 0.008316120132803917\n"
     ]
    }
   ],
   "source": [
    "# Load data from load_path\n",
    "load_data = {}\n",
    "assert opts.load_path is None or opts.resume is None, \"Only one of load path and resume can be given\"\n",
    "load_path = opts.load_path if opts.load_path is not None else opts.resume\n",
    "if load_path is not None:\n",
    "    print('  [*] Loading data from {}'.format(load_path))\n",
    "    load_data = load_data = torch_load_cpu(load_path)\n",
    "\n",
    "# Initialize model\n",
    "model_class = AttentionModel\n",
    "model = maybe_cuda_model(\n",
    "    model_class(\n",
    "        opts.embedding_dim,\n",
    "        opts.hidden_dim,\n",
    "        problem,\n",
    "        n_encode_layers=opts.n_encode_layers,\n",
    "        mask_inner=True,\n",
    "        mask_logits=True,\n",
    "        normalization=opts.normalization,\n",
    "        tanh_clipping=opts.tanh_clipping\n",
    "    ),\n",
    "    opts.use_cuda\n",
    ")\n",
    "\n",
    "# Overwrite model parameters by parameters to load\n",
    "model_ = get_inner_model(model)\n",
    "model_.load_state_dict({**model_.state_dict(), **load_data.get('model', {})})\n",
    "\n",
    "# Initialize baseline\n",
    "baseline = CriticBaseline(\n",
    "            maybe_cuda_model(\n",
    "                CriticNetwork(\n",
    "                    2,\n",
    "                    opts.embedding_dim,\n",
    "                    opts.hidden_dim,\n",
    "                    opts.n_encode_layers,\n",
    "                    opts.normalization\n",
    "                ),\n",
    "                opts.use_cuda\n",
    "            )\n",
    "        )\n",
    "# Load baseline from data, make sure script is called with same type of baseline\n",
    "if 'baseline' in load_data:\n",
    "    baseline.load_state_dict(load_data['baseline'])\n",
    "l=[]\n",
    "if opts.eval_only:\n",
    "    for i in range(8):\n",
    "        best = validate(model, val_dataset, opts)\n",
    "        l.append(best)\n",
    "\n",
    "\n",
    "    \n",
    "    print('Best solutions: {} +- {}'.format(\n",
    "    best.mean().item(), torch.std(best) / math.sqrt(len(best))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
