{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboard_logger import Logger as TbLogger\n",
    "\n",
    "from critic_network import CriticNetwork\n",
    "from options import get_options\n",
    "from train import train_epoch, get_inner_model   ##########  no need for validate now\n",
    "from baselines import NoBaseline, ExponentialBaseline, CriticBaseline, RolloutBaseline, WarmupBaseline\n",
    "from attention_model import AttentionModel\n",
    "from utils import torch_load_cpu, load_model, maybe_cuda_model, load_problem\n",
    "from itertools import combinations, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp.pprint(vars(opts))\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(opts.seed)\n",
    "\n",
    "# Optionally configure tensorboard\n",
    "tb_logger = None\n",
    "if not opts.no_tensorboard:\n",
    "    tb_logger = TbLogger(os.path.join(opts.log_dir, \"{}_{}\".format(opts.problem, opts.graph_size), opts.run_name))\n",
    "\n",
    "\n",
    "os.makedirs(opts.save_dir)\n",
    "# Save arguments so exact configuration can always be found\n",
    "with open(os.path.join(opts.save_dir, \"args.json\"), 'w') as f:\n",
    "    json.dump(vars(opts), f, indent=True)\n",
    "\n",
    "# Figure out what's the problem\n",
    "problem = load_problem(opts.problem)\n",
    "\n",
    "# Load data from load_path\n",
    "load_data = {}\n",
    "assert opts.load_path is None or opts.resume is None, \"Only one of load path and resume can be given\"\n",
    "load_path = opts.load_path if opts.load_path is not None else opts.resume\n",
    "if load_path is not None:\n",
    "    print('  [*] Loading data from {}'.format(load_path))\n",
    "    load_data = load_data = torch_load_cpu(load_path)\n",
    "\n",
    "# Initialize model\n",
    "model_class = AttentionModel\n",
    "model = maybe_cuda_model(\n",
    "    model_class(\n",
    "        opts.embedding_dim,\n",
    "        opts.hidden_dim,\n",
    "        problem,\n",
    "        n_encode_layers=opts.n_encode_layers,\n",
    "        mask_inner=True,\n",
    "        mask_logits=True,\n",
    "        normalization=opts.normalization,\n",
    "        tanh_clipping=opts.tanh_clipping\n",
    "    ),\n",
    "    opts.use_cuda\n",
    ")\n",
    "\n",
    "# Overwrite model parameters by parameters to load\n",
    "model_ = get_inner_model(model)\n",
    "model_.load_state_dict({**model_.state_dict(), **load_data.get('model', {})})\n",
    "\n",
    "\n",
    "# Initialize old policy\n",
    "model_old = AttentionModel\n",
    "policy_old = maybe_cuda_model(\n",
    "    model_old(\n",
    "        opts.embedding_dim,\n",
    "        opts.hidden_dim,\n",
    "        problem,\n",
    "        n_encode_layers=opts.n_encode_layers,\n",
    "        mask_inner=True,\n",
    "        mask_logits=True,\n",
    "        normalization=opts.normalization,\n",
    "        tanh_clipping=opts.tanh_clipping\n",
    "    ),\n",
    "    opts.use_cuda\n",
    ")\n",
    "\n",
    "policy_old.load_state_dict(model.state_dict())\n",
    "\n",
    "# Initialize baseline\n",
    "baseline = CriticBaseline(\n",
    "            maybe_cuda_model(\n",
    "                CriticNetwork(\n",
    "                    7,\n",
    "                    opts.embedding_dim,\n",
    "                    opts.hidden_dim,\n",
    "                    opts.n_encode_layers,\n",
    "                    opts.normalization\n",
    "                ),\n",
    "                opts.use_cuda\n",
    "            )\n",
    "        )\n",
    "# Load baseline from data, make sure script is called with same type of baseline\n",
    "if 'baseline' in load_data:\n",
    "    baseline.load_state_dict(load_data['baseline'])\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(\n",
    "    [{'params': model.parameters(), 'lr': opts.lr_model}]\n",
    "    + (\n",
    "        [{'params': baseline.get_learnable_parameters(), 'lr': opts.lr_critic}]\n",
    "        if len(baseline.get_learnable_parameters()) > 0\n",
    "        else []\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load optimizer state\n",
    "if 'optimizer' in load_data:\n",
    "    optimizer.load_state_dict(load_data['optimizer'])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            # if isinstance(v, torch.Tensor):\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "\n",
    "# Initialize learning rate scheduler, decay by lr_decay once per epoch!\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: opts.lr_decay ** epoch)\n",
    "\n",
    "# Start the actual training loop\n",
    "val_dataset = problem.make_dataset(size=opts.graph_size, num_samples=opts.val_size, filename=opts.val_dataset)\n",
    "\n",
    "# # prepare for 2opt mask\n",
    "o=torch.tensor([i for i in range(128)])\n",
    "oo = o\n",
    "CL=list(combinations(o, 2))\n",
    "lis=[]\n",
    "for i in CL:\n",
    "    ooo = oo.clone()\n",
    "    ooo[i[0]:i[1]+1]=torch.flip(oo[i[0]:i[1]+1],[0]).clone()\n",
    "    lis.append(ooo)\n",
    "dic = torch.stack(lis,0)\n",
    "\n",
    "if opts.resume:\n",
    "    epoch_resume = int(os.path.splitext(os.path.split(opts.resume)[-1])[0].split(\"-\")[1])\n",
    "\n",
    "    torch.set_rng_state(load_data['rng_state'])\n",
    "    if opts.use_cuda:\n",
    "        torch.cuda.set_rng_state_all(load_data['cuda_rng_state'])\n",
    "    # Set the random states\n",
    "    # Dumping of state was done before epoch callback, so do that now (model is loaded)\n",
    "    baseline.epoch_callback(model, epoch_resume)\n",
    "    print(\"Resuming after {}\".format(epoch_resume))\n",
    "    opts.epoch_start = epoch_resume + 1\n",
    "\n",
    "if opts.eval_only:\n",
    "    validate(model, val_dataset, opts)\n",
    "else:\n",
    "    for epoch in range(opts.epoch_start, opts.epoch_start + opts.n_epochs):\n",
    "        train_epoch(\n",
    "            model,\n",
    "            policy_old,\n",
    "            optimizer,\n",
    "            baseline,\n",
    "            lr_scheduler,\n",
    "            epoch,\n",
    "            val_dataset,\n",
    "            problem,\n",
    "            tb_logger,\n",
    "            dic,\n",
    "            CL,\n",
    "            opts\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
